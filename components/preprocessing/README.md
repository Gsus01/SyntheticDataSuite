# Preprocesador de Series Temporales

Microservicio de preprocesamiento de datos para series temporales, diseÃ±ado para ejecutarse de forma aislada en workflows de Argo. Permite el procesamiento configurable de archivos CSV con mÃºltiples opciones de preprocesamiento especÃ­ficas para datos temporales.

## ğŸš€ CaracterÃ­sticas

- **Preprocesamiento configurable** mediante archivos YAML
- **DetecciÃ³n automÃ¡tica** de columnas temporales (con opciÃ³n de formato especÃ­fico)
- **Manejo de valores faltantes** con mÃºltiples estrategias
- **DetecciÃ³n y manejo de outliers** (IQR y Z-score)
- **NormalizaciÃ³n de datos** (MinMax, Z-score, Robust)
- **Remuestreo temporal** para datos irregulares
- **Ventanas deslizantes** para anÃ¡lisis temporal
- **SelecciÃ³n de caracterÃ­sticas** configurable
- **EjecuciÃ³n en Docker** para aislamiento completo
- **Tests exhaustivos** con pytest (unitarios, integraciÃ³n, caja negra)

## ğŸ“‹ Requisitos

- Python 3.11+
- Docker (opcional, para ejecuciÃ³n aislada)
- Dependencias: pandas, numpy, PyYAML, pytest (ver `requirements.txt`)

## ğŸ› ï¸ InstalaciÃ³n

### OpciÃ³n 1: EjecuciÃ³n Local

```bash
# Instalar dependencias (incluye pytest)
pip install -r requirements.txt
```
Los datos de prueba necesarios se encuentran en el directorio `test_data/`.

### OpciÃ³n 2: Docker

```bash
# Construir imagen
docker build -t timeseries-preprocessor .

# O usar el script de utilidad
./run.sh build
```

## ğŸ“– Uso

### EjecuciÃ³n BÃ¡sica

```bash
python preprocess.py --config config.yaml --input data.csv --output processed_data.csv
```

### Con Docker

```bash
docker run --rm \
  -v $(pwd)/config.yaml:/app/config.yaml:ro \
  -v $(pwd)/data.csv:/app/data/input/data.csv:ro \
  -v $(pwd)/output:/app/data/output \
  timeseries-preprocessor \
  --config /app/config.yaml \
  --input /app/data/input/data.csv \
  --output /app/data/output/processed.csv
```

### Con Docker Compose

```bash
# Procesamiento Ãºnico (usando el servicio 'timeseries-preprocessor')
docker-compose up timeseries-preprocessor

# Procesamiento en lote
docker-compose --profile batch up batch-processor
```

### Script de Utilidad

```bash
# Ejecutar demo completo
./run.sh demo

# Ejecutar tests (actualizado para pytest)
./run.sh test

# Procesar archivo especÃ­fico
./run.sh run --input data.csv --output processed.csv

# Procesar con Docker
./run.sh run --input data.csv --output processed.csv --docker
```

## âš™ï¸ ConfiguraciÃ³n

El procesamiento se configura mediante archivos YAML. Ejemplo de configuraciÃ³n (`config.yaml`):

```yaml
# ConfiguraciÃ³n de logging
logging:
  level: INFO

# ConfiguraciÃ³n de datos
data:
  datetime_column: null  # Auto-detecciÃ³n si es null
  datetime_format: null  # Opcional, ej: "%Y-%m-%d %H:%M:%S" o "%d/%m/%Y %H:%M". Si es null, se intenta auto-detecciÃ³n.

# Pipeline de preprocesamiento
preprocessing:
  # SelecciÃ³n de caracterÃ­sticas
  features:
    # include: ["timestamp", "value", "sensor_1"]
    # exclude: ["id", "metadata"]
    
  # Manejo de valores faltantes
  missing_values:
    strategy: "fill"  # "drop" o "fill"
    method: "interpolate"  # "forward", "backward", "interpolate", "mean"
    threshold: 0.5  # Para strategy="drop"
    
  # DetecciÃ³n de outliers
  outliers:
    enabled: true
    method: "iqr"  # "iqr" o "zscore"
    threshold: 3   # Para mÃ©todo zscore
    action: "cap"  # "remove" o "cap"
    
  # NormalizaciÃ³n
  normalization:
    enabled: true
    method: "minmax"  # "minmax", "zscore", "robust"
    
  # Remuestreo temporal
  resampling:
    enabled: false
    frequency: "h"  # Ej: "1min", "5min", "h" (hora), "D" (dÃ­a)
    method: "mean"   # "mean", "sum", "first", "last"
    
  # Ventanas deslizantes
  sliding_windows:
    enabled: true
    size: 5
    features: []  # VacÃ­o = todas las numÃ©ricas
```

## ğŸ“ Estructura del Proyecto

```
components/preprocessing/
â”œâ”€â”€ preprocess.py              # MÃ³dulo principal del preprocesador
â”œâ”€â”€ config.yaml               # ConfiguraciÃ³n por defecto
â”œâ”€â”€ batch_config.yaml         # ConfiguraciÃ³n para lote
â”œâ”€â”€ requirements.txt          # Dependencias Python (incluye pytest)
â”œâ”€â”€ Dockerfile               # Imagen Docker
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n de contenedores (incluye servicio para black-box tests)
â”œâ”€â”€ run.sh                   # Script de utilidad (actualizado para pytest)
â”œâ”€â”€ test_data/               # Datos de prueba para integraciÃ³n y black-box
â”‚   â”œâ”€â”€ sensor_data_with_nulls.csv
â”‚   â”œâ”€â”€ financial_data_with_outliers.csv
â”‚   â”œâ”€â”€ irregular_timestamp_data.csv
â”‚   â””â”€â”€ mixed_data_types.csv
â”œâ”€â”€ tests/                   # Directorio principal de tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unit/                # Tests Unitarios
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_preprocessor_units.py
â”‚   â”œâ”€â”€ integration/         # Tests de IntegraciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_preprocessor_integration.py
â”‚   â””â”€â”€ blackbox/            # Tests de Caja Negra (Black-Box)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_container_execution.py
â””â”€â”€ README.md                # Este archivo
```

## ğŸ§ª Tests

El proyecto utiliza `pytest` para un testing exhaustivo por capas, cubriendo tests unitarios, de integraciÃ³n y de caja negra (black-box).

### Estructura de los Tests

- **Tests Unitarios (`tests/unit/`)**: Prueban funciones y mÃ©todos individuales de la clase `TimeSeriesPreprocessor` de forma aislada. Se centran en la lÃ³gica interna sin depender de I/O de ficheros reales o Docker.
- **Tests de IntegraciÃ³n (`tests/integration/`)**: Verifican que el pipeline completo de preprocesamiento (`process` method) funciona como se espera, incluyendo la lectura de ficheros CSV de prueba (de `test_data/`) y la escritura de resultados. Utilizan configuraciones especÃ­ficas y la fixture `tmp_path` de pytest para manejar ficheros temporales.
- **Tests de Caja Negra (`tests/blackbox/`)**: Prueban la imagen Docker construida como una unidad cerrada. Simulan cÃ³mo se ejecutarÃ­a el servicio en un entorno de producciÃ³n (ej. Argo Workflows). Utilizan `docker-compose` para ejecutar el contenedor con datos y configuraciones montadas, verificando los ficheros de salida. El servicio `blackbox-test-runner` en `docker-compose.yml` estÃ¡ dedicado a esto.

### Datos de Prueba

Los datos de prueba se encuentran en el directorio `test_data/` y son utilizados por los tests de integraciÃ³n y caja negra:

1.  **sensor_data_with_nulls.csv**: Datos de sensores IoT con valores nulos.
2.  **financial_data_with_outliers.csv**: Datos financieros con outliers extremos.
3.  **irregular_timestamp_data.csv**: Timestamps irregulares con gaps y formatos mixtos.
4.  **mixed_data_types.csv**: Tipos de datos mixtos y formatos inconsistentes.

### EjecuciÃ³n de Tests

AsegÃºrate de tener `pytest` instalado (incluido en `requirements.txt`):
```bash
# Desde components/preprocessing/
pip install -r requirements.txt
```

**1. Ejecutar todos los tests:**
Desde el directorio `components/preprocessing/`:
```bash
python3 -m pytest tests/
```
O simplemente (si pytest estÃ¡ en el PATH y el entorno reconoce los mÃ³dulos locales):
```bash
pytest tests/
```

**2. Ejecutar tests de una capa especÃ­fica:**
Desde el directorio `components/preprocessing/`:
```bash
# Tests Unitarios
python3 -m pytest tests/unit/

# Tests de IntegraciÃ³n
python3 -m pytest tests/integration/

# Tests de Caja Negra (requieren Docker y Docker Compose v1 o v2)
# AsegÃºrate que Docker estÃ¡ corriendo y docker-compose (o docker compose) estÃ¡ en tu PATH
python3 -m pytest tests/blackbox/
```

**3. Usar el script de utilidad `run.sh`:**
El script ha sido actualizado para usar `pytest`.
```bash
# Desde components/preprocessing/
./run.sh test
```

**4. Ver mÃ¡s detalles y logs:**
Usa las opciones de `pytest` para mayor verbosidad (desde `components/preprocessing/`):
```bash
python3 -m pytest -s -v tests/
```
Para los tests de caja negra, los logs del contenedor tambiÃ©n pueden ser inspeccionados (la salida de `docker compose run` o `docker-compose run` incluye stdout/stderr del contenedor, que son capturados por pytest).

### Demo
El comando de demo sigue disponible:
```bash
# Desde components/preprocessing/
./run.sh demo
```

## ğŸ³ Docker

### Dockerfile

El contenedor estÃ¡ optimizado para:
- **TamaÃ±o mÃ­nimo**: Base Python 3.11-slim.
- **Seguridad**: Usuario no-root (`preprocessor`).
- **Flexibilidad**: VolÃºmenes montables para datos y configuraciÃ³n.
- **Logging**: Output sin buffer para mejor observabilidad.
- Incluye `config.yaml` por defecto en `/app/config.yaml`.

### Docker Compose

El fichero `docker-compose.yml` define varios servicios, incluyendo:
- `timeseries-preprocessor`: Para ejecuciÃ³n Ãºnica del preprocesador.
- `batch-processor`: Para procesamiento en lote (activado con `--profile batch`).
- `blackbox-test-runner`: Servicio base utilizado por los tests de caja negra.

## ğŸ”§ IntegraciÃ³n con Argo Workflows

Ejemplo de uso en Argo Workflows:

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: preprocess-timeseries
spec:
  entrypoint: preprocess-data
  templates:
  - name: preprocess-data
    container:
      image: timeseries-preprocessor:latest # AsegÃºrate que esta imagen estÃ¡ disponible en tu registro
      command: ["python", "preprocess.py"]
      args: [
        "--config", "/app/config.yaml", # Puede ser el config.yaml por defecto en la imagen o uno montado
        "--input", "/data/input/raw_data.csv",
        "--output", "/data/output/processed_data.csv"
      ]
      volumeMounts:
      - name: config-volume # Opcional: si quieres montar un configMap como config.yaml
        mountPath: /app/config.yaml # SobrescribirÃ­a el de la imagen
        subPath: config.yaml # Asumiendo que tu configMap tiene una clave config.yaml
      - name: data-input-volume
        mountPath: /data/input # Directorio para datos de entrada
      - name: data-output-volume
        mountPath: /data/output # Directorio para datos de salida
  volumes:
  - name: config-volume
    configMap:
      name: preprocessing-config # Nombre de tu ConfigMap
  - name: data-input-volume
    persistentVolumeClaim: # O cualquier otro tipo de volumen
      claimName: input-data-pvc
  - name: data-output-volume
    persistentVolumeClaim:
      claimName: output-data-pvc
```
AsegÃºrate de que la imagen `timeseries-preprocessor:latest` estÃ© accesible para tu clÃºster de Argo y que los volÃºmenes y ConfigMaps estÃ©n configurados correctamente.

## ğŸ“Š Funcionalidades de Preprocesamiento

(Esta secciÃ³n parece estar actualizada y no requiere cambios inmediatos basados en la refactorizaciÃ³n de tests)

### DetecciÃ³n de Columnas Temporales
- Auto-detecciÃ³n por nombre (date, time, timestamp)
- Auto-detecciÃ³n por contenido
- OpciÃ³n para especificar formato de fecha/tiempo (`data.datetime_format`)
- ConversiÃ³n automÃ¡tica a datetime
- IndexaciÃ³n temporal

### Manejo de Valores Faltantes
- **Drop**: Eliminar filas/columnas con umbrales configurables
- **Fill**: Rellenar con forward/backward fill, interpolaciÃ³n o media

### DetecciÃ³n de Outliers
- **IQR Method**: Rango intercuartÃ­lico (Q1-1.5*IQR, Q3+1.5*IQR)
- **Z-Score**: DesviaciÃ³n estÃ¡ndar configurable
- **Acciones**: Eliminar o limitar valores

### NormalizaciÃ³n
- **MinMax**: Escalar a [0,1]
- **Z-Score**: Media 0, desviaciÃ³n 1
- **Robust**: Mediana y rango intercuartÃ­lico

### Remuestreo Temporal
- Frecuencias configurables (minutos, horas, dÃ­as)
- MÃ©todos de agregaciÃ³n (media, suma, primero, Ãºltimo)
- Manejo automÃ¡tico de Ã­ndices temporales

### Ventanas Deslizantes
- Media mÃ³vil y desviaciÃ³n estÃ¡ndar
- TamaÃ±o de ventana configurable
- Aplicable a columnas especÃ­ficas o todas las numÃ©ricas

## ğŸš¨ Manejo de Errores

El preprocesador incluye manejo robusto de errores:
- ValidaciÃ³n de archivos de entrada
- Logging detallado de operaciones
- Manejo de tipos de datos inconsistentes
- RecuperaciÃ³n de errores de parsing temporal (convierte a NaT y puede eliminar filas)

## ğŸ“ˆ Logging y Monitoreo

- Logging estructurado con timestamps
- Niveles configurables (DEBUG, INFO, WARNING, ERROR)
- MÃ©tricas de procesamiento (filas originales vs finales)
- Output compatible con sistemas de monitoreo

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crear rama de feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver `LICENSE` para mÃ¡s detalles. (Asumiendo que existe un archivo LICENSE, si no, esta lÃ­nea podrÃ­a necesitar ajuste)

## ğŸ†˜ Soporte

Para reportar problemas o solicitar funcionalidades:
1. Crear un issue en el repositorio
2. Incluir logs de error y configuraciÃ³n utilizada
3. Proporcionar datos de ejemplo si es posible
