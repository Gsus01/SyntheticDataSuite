# 5.3. Representación del Modelo de Datos del Flujo

## Introducción

Este apartado describe cómo se representa internamente un flujo de trabajo visual: la estructura de datos que lo define, cómo se serializa para persistirlo, dónde se almacena, y las consideraciones sobre control de usuarios en la arquitectura objetivo.

El modelo de datos del flujo es el puente entre la representación visual del canvas (lo que ve el usuario) y el manifiesto ejecutable de Argo Workflows (lo que procesa el clúster).

---

## Estructura del Grafo Visual

Un flujo de trabajo se representa como un **grafo dirigido** compuesto por dos colecciones:

| Colección | Descripción |
|:----------|:------------|
| **nodes** | Lista de nodos, cada uno representa un paso del workflow |
| **edges** | Lista de aristas, cada una representa una conexión entre nodos |

Esta estructura sigue el modelo de React Flow y es directamente serializable a JSON.

---

## Estructura de un Nodo

Cada nodo del grafo tiene la siguiente estructura:

```typescript
interface FlowNode {
  id: string;                      // Identificador único del nodo
  type: "nodeInput" | "nodeDefault" | "nodeOutput";  // Tipo visual
  position: { x: number; y: number };  // Posición en el canvas
  data: FlowNodeData;              // Datos específicos del nodo
}
```

### FlowNodeData

Los datos específicos de cada nodo contienen la información de configuración:

```typescript
interface FlowNodeData {
  label: string;                   // Etiqueta visible en el canvas
  tone?: string;                   // Categoría visual (input, training, etc.)
  templateName?: string;           // Nombre del template del catálogo
  parameterKeys?: string[];        // Claves de parámetros configurables
  parameterDefaults?: Record<string, unknown>;  // Valores por defecto
  parameters?: Record<string, unknown>;         // Valores modificados por usuario
  uploadedArtifact?: NodeArtifact;              // Fichero subido (nodos input)
  artifactPorts?: FlowNodePorts;   // Puertos de conexión
  runtimeStatus?: WorkflowNodeRuntimeStatus;    // Estado durante ejecución
}
```

### Artefacto Subido

Para nodos que reciben ficheros de entrada:

```typescript
interface NodeArtifact {
  bucket: string;          // Bucket de MinIO
  key: string;             // Path dentro del bucket
  size: number;            // Tamaño en bytes
  contentType?: string;    // MIME type
  originalFilename?: string;  // Nombre original del fichero
}
```

### Puertos de Conexión

Cada nodo define sus puntos de conexión:

```typescript
interface FlowNodePorts {
  inputs: NodeArtifactPort[];   // Artefactos que recibe
  outputs: NodeArtifactPort[];  // Artefactos que produce
}

interface NodeArtifactPort {
  name: string;       // Nombre lógico (ej: "processed-data")
  path?: string;      // Ruta dentro del contenedor
}
```

---

## Estructura de una Arista

Las conexiones entre nodos se representan como aristas:

```typescript
interface FlowEdge {
  id: string;               // Identificador único
  source: string;           // ID del nodo origen
  target: string;           // ID del nodo destino
  sourceHandle?: string;    // Puerto de salida específico
  targetHandle?: string;    // Puerto de entrada específico
}
```

Los handles opcionales permiten conectar a puertos específicos cuando un nodo tiene múltiples entradas o salidas.

---

## Ejemplo de Grafo Serializado

Un workflow sencillo con preprocesamiento y entrenamiento:

```json
{
  "nodes": [
    {
      "id": "node-1",
      "type": "nodeInput",
      "position": { "x": 100, "y": 100 },
      "data": {
        "label": "data-input",
        "templateName": "data-input",
        "uploadedArtifact": {
          "bucket": "argo-artifacts",
          "key": "sessions/abc123/nodes/node-1/dataset.csv",
          "size": 245000,
          "contentType": "text/csv",
          "originalFilename": "mi_dataset.csv"
        }
      }
    },
    {
      "id": "node-2",
      "type": "nodeDefault",
      "position": { "x": 350, "y": 100 },
      "data": {
        "label": "preprocessing",
        "templateName": "preprocessing",
        "tone": "preprocessing",
        "parameterDefaults": { "normalize": true },
        "parameters": { "normalize": false },
        "artifactPorts": {
          "inputs": [
            { "name": "source-data", "path": "/data/inputs/input.csv" }
          ],
          "outputs": [
            { "name": "processed-data", "path": "/data/outputs/preprocessed.csv" }
          ]
        }
      }
    },
    {
      "id": "node-3",
      "type": "nodeDefault",
      "position": { "x": 600, "y": 100 },
      "data": {
        "label": "train-hmm-model",
        "templateName": "train-hmm-model",
        "tone": "training"
      }
    }
  ],
  "edges": [
    { "id": "e1-2", "source": "node-1", "target": "node-2" },
    { "id": "e2-3", "source": "node-2", "target": "node-3" }
  ]
}
```

---

## Serialización y Persistencia

### Proceso de Guardado

Cuando el usuario guarda un workflow, ocurre el siguiente proceso:

1. **Sanitización**: Se eliminan datos transitorios (`runtimeStatus`) que no deben persistirse.
2. **Serialización**: El grafo se convierte a JSON.
3. **Envoltura**: Se añaden metadatos (nombre, descripción, timestamps).
4. **Almacenamiento**: Se sube a MinIO como fichero JSON.

![Serialization Flow](diagrams/5.3-serialization-flow.puml)

### Estructura del Registro Persistido

El registro completo que se almacena incluye:

```typescript
interface StoredWorkflowRecord {
  // Identificación
  workflowId: string;          // UUID único
  name: string;                // Nombre dado por el usuario
  description?: string;        // Descripción opcional
  sessionId: string;           // ID de sesión del canvas
  
  // Contenido del grafo
  nodes: FlowNode[];           // Lista de nodos
  edges: FlowEdge[];           // Lista de aristas
  
  // Compilación
  compiledManifest?: string;   // YAML de Argo (si está compilado)
  manifestFilename?: string;   // Nombre del fichero de manifiesto
  compiledAt?: string;         // Timestamp de compilación
  nodeSlugMap: Record<string, string>;  // Mapeo node.id → slug de Argo
  
  // Última ejecución
  lastWorkflowName?: string;   // Nombre en Argo de la última ejecución
  lastNamespace?: string;      // Namespace de Kubernetes
  lastSubmittedAt?: string;    // Timestamp de último envío
  lastBucket?: string;         // Bucket del manifiesto
  lastKey?: string;            // Key del manifiesto
  
  // Metadatos
  createdAt: string;           // Fecha de creación (ISO 8601)
  updatedAt: string;           // Fecha de última modificación
  version: number;             // Versión del registro (para conflictos)
}
```

### Ubicación del Almacenamiento

| Aspecto | Prototipo | Arquitectura Objetivo |
|:--------|:----------|:----------------------|
| **Tecnología** | MinIO (S3-compatible) | MinIO + PostgreSQL |
| **Bucket** | `argo-artifacts` | `dtwin-workflows` |
| **Path** | `workflows/{workflowId}.json` | PostgreSQL (metadatos) + S3 (grafo) |
| **Formato** | JSON completo | Híbrido: metadatos en BD, grafo en JSON |

### Proceso de Carga

Al cargar un workflow guardado:

1. **Recuperación**: Se descarga el JSON de MinIO.
2. **Validación**: Se verifica la estructura con Pydantic.
3. **Enriquecimiento**: Se añaden puertos de artefactos desde el catálogo si faltan.
4. **Restauración**: Se reconstruye el estado del canvas.

---

## Diagrama de Clases

![Data Model Classes](diagrams/5.3-data-model-classes.puml)

---

## Control de Usuarios

### Estado del Prototipo

El prototipo actual **no implementa control de usuarios**. Todos los workflows son accesibles por cualquier persona que tenga acceso a la interfaz. No hay:

- Autenticación de usuarios.
- Propiedad de workflows.
- Permisos de lectura/escritura.

### Arquitectura Objetivo

En la arquitectura objetivo, el control de usuarios se implementaría de la siguiente forma:

#### Modelo de Propiedad

```typescript
interface WorkflowOwnership {
  workflowId: string;
  ownerId: string;           // Usuario que creó el workflow
  visibility: "private" | "team" | "public";
  sharedWith?: string[];     // IDs de usuarios con acceso
}
```

#### Roles y Permisos

| Rol | Permisos |
|:----|:---------|
| **owner** | Lectura, escritura, eliminación, compartir |
| **editor** | Lectura, escritura |
| **viewer** | Solo lectura |
| **admin** | Acceso total a todos los workflows |

#### Flujo de Autorización

1. Usuario se autentica (OAuth2/OIDC).
2. API Gateway valida el token JWT.
3. Backend consulta permisos del usuario sobre el workflow.
4. Si autorizado, devuelve los datos; si no, error 403.

#### Almacenamiento de Permisos

| Elemento | Almacenamiento |
|:---------|:---------------|
| **Usuarios y roles** | PostgreSQL (`users`, `roles`) |
| **Permisos de workflow** | PostgreSQL (`workflow_permissions`) |
| **Workflow (grafo)** | MinIO (JSON) |

---

## Consideraciones de Versionado

### Estado del Prototipo

En el prototipo, cada guardado **sobrescribe** la versión anterior. El campo `version` existe en el modelo pero no se utiliza para control de conflictos.

### Arquitectura Objetivo

Para producción se recomienda:

| Estrategia | Descripción |
|:-----------|:------------|
| **Versionado explícito** | Cada guardado crea una nueva versión, las anteriores se conservan |
| **Detección de conflictos** | Si otro usuario modificó mientras editabas, se avisa antes de sobrescribir |
| **Historial navegable** | Poder ver y restaurar versiones anteriores |
| **Diff visual** | Comparar dos versiones del mismo workflow |

---

## Resumen

| Aspecto | Prototipo | Arquitectura Objetivo |
|:--------|:----------|:----------------------|
| **Formato** | JSON | JSON (grafo) + SQL (metadatos) |
| **Almacenamiento** | MinIO | MinIO + PostgreSQL |
| **Serialización** | JSON.stringify | JSON + Pydantic validation |
| **Control de usuarios** | No implementado | OAuth2 + RBAC |
| **Versionado** | Sobrescritura | Historial de versiones |
| **Validación** | Pydantic en backend | Pydantic + esquema JSON |
