# 4.1. Catálogo de Servicios y API

## Introducción

Este apartado describe los servicios que componen el software de gestión y control de la plataforma. Se detalla tanto la **arquitectura objetivo** (el diseño completo para producción) como el **estado actual del prototipo** (la implementación simplificada para validación técnica).

En la arquitectura objetivo, el sistema se descompone en múltiples servicios especializados. Sin embargo, el prototipo actual consolida la mayor parte de la lógica en un único backend monolítico para facilitar el desarrollo y la validación inicial.

---

## Arquitectura Objetivo: Servicios Desacoplados

La visión final de la plataforma contempla una arquitectura basada en servicios independientes, cada uno con una responsabilidad bien definida. Esta separación permite escalar, mantener y evolucionar cada componente de forma independiente.

### Catálogo de Servicios Objetivo

| Servicio | Responsabilidad | Tecnología Sugerida |
|:---------|:----------------|:--------------------|
| **API Gateway** | Punto de entrada único, enrutamiento, rate limiting, autenticación | Kong / Traefik / Envoy |
| **Auth Service** | Autenticación (OAuth2/OIDC), gestión de tokens, RBAC | Keycloak / Auth0 / Custom |
| **Workflow Service** | CRUD de definiciones de workflow, compilación a manifiestos | FastAPI / Go |
| **Execution Service** | Interacción con Argo: submit, status, logs | FastAPI / Go |
| **Artifact Service** | Gestión de artefactos: upload, download, preview, retención | FastAPI / Go |
| **Catalog Service** | Gestión del catálogo de nodos, versionado de templates | FastAPI / Go |
| **Notification Service** | Webhooks, alertas por email, eventos de finalización | FastAPI / Node.js |
| **Metadata Service** | Histórico de ejecuciones, auditoría, métricas de negocio | FastAPI / Go |

![Target Services Architecture](diagrams/4.1-target-services.puml)

### Descripción de Servicios Objetivo

#### API Gateway

El API Gateway actúa como punto de entrada único para todas las peticiones externas. Sus responsabilidades incluyen:

- **Autenticación centralizada**: Valida tokens JWT antes de pasar las peticiones a los servicios internos.
- **Rate Limiting**: Protege contra abusos limitando peticiones por usuario/IP.
- **Enrutamiento**: Dirige las peticiones al servicio correspondiente basándose en el path.
- **Logging y métricas**: Registra todas las peticiones para auditoría.

#### Auth Service

Gestiona la identidad y los permisos de los usuarios:

- **Autenticación**: Soporta múltiples proveedores (LDAP, OAuth2, SAML).
- **Autorización (RBAC)**: Define roles (admin, developer, viewer) y permisos por recurso.
- **Gestión de sesiones**: Emisión y revocación de tokens.
- **Auditoría de accesos**: Registro de quién accedió a qué y cuándo.

#### Workflow Service

Responsable del ciclo de vida de las definiciones de workflow:

- **CRUD de workflows**: Crear, leer, actualizar, eliminar definiciones.
- **Compilación**: Traduce el grafo visual (JSON) a manifiestos de Argo (YAML).
- **Validación**: Comprueba que el DAG es válido (sin ciclos, sin nodos huérfanos).
- **Versionado**: Mantiene historial de versiones de cada workflow.

#### Execution Service

Maneja la ejecución de workflows en el clúster:

- **Envío a Argo**: Ejecuta `argo submit` con el manifiesto generado.
- **Consulta de estado**: Polling periódico o webhooks para actualizar el estado.
- **Streaming de logs**: Proporciona logs en tiempo real de cada paso.
- **Gestión de reintentos**: Permite re-ejecutar pasos fallidos.

#### Artifact Service

Gestiona todos los ficheros que fluyen por el sistema:

- **Upload**: Recibe ficheros del usuario, los almacena en S3 con metadatos.
- **Download**: Permite descargar artefactos de salida.
- **Preview**: Genera previsualizaciones para tipos conocidos (CSV, JSON, imágenes).
- **Retención**: Aplica políticas de limpieza para artefactos antiguos.

#### Catalog Service

Mantiene el catálogo de nodos disponibles:

- **Registro de nodos**: Define qué tipos de procesamiento están disponibles.
- **Versionado**: Cada nodo tiene versión; permite deprecar versiones antiguas.
- **Metadatos**: Parámetros configurables, artefactos de entrada/salida, límites de recursos.
- **Validación de imágenes**: Comprueba que las imágenes Docker existen.

#### Notification Service

Gestiona la comunicación con usuarios y sistemas externos:

- **Webhooks**: Notifica a sistemas externos cuando un workflow termina.
- **Email**: Envía alertas por correo (éxito, fallo, alertas de cuota).
- **Integración con Slack/Teams**: Mensajes a canales de equipo.

#### Metadata Service

Almacena información estructurada para análisis y auditoría:

- **Histórico de ejecuciones**: Quién ejecutó qué, cuándo, con qué resultado.
- **Métricas de uso**: Tiempo de ejecución, recursos consumidos, costes.
- **Dashboards**: Datos para Grafana o herramientas de BI.

---

## Estado del Prototipo: Backend Monolítico

El prototipo actual consolida toda la lógica en un **único servicio backend** implementado con FastAPI. Esta decisión simplifica el desarrollo inicial, reduce la complejidad operativa y permite validar el flujo completo sin la sobrecarga de gestionar múltiples servicios.

### Diagrama de Componentes del Backend

![Backend Components](diagrams/4.1-backend-components.puml)

### Módulos del Backend

El backend está organizado en módulos con responsabilidades claramente separadas, lo que facilitará una eventual migración a servicios independientes:

| Módulo | Archivo | Responsabilidad |
|:-------|:--------|:----------------|
| **API Layer** | `main.py` | Definición de endpoints REST, validación de requests, serialización de responses |
| **Workflow Builder** | `workflow_builder.py` | Traduce grafos visuales (JSON) a manifiestos de Argo (YAML) |
| **Workflow Store** | `workflow_store.py` | Persistencia de definiciones de workflow en MinIO (JSON) |
| **Catalog Loader** | `catalog_loader.py` | Carga el catálogo de nodos desde `catalog/nodes.yaml` |
| **MinIO Helper** | `minio_helper.py` | Abstracción del cliente S3 para operaciones de almacenamiento |
| **Argo Client** | `argo_client.py` | Comunicación con Argo Server para consultar estado y logs |
| **Image Validator** | `image_validator.py` | Valida que las imágenes Docker existen en el registro |

### API REST Expuesta

El backend expone los siguientes endpoints, que en la arquitectura objetivo se distribuirían entre diferentes servicios:

#### Endpoints de Artefactos

| Método | Ruta | Descripción | Servicio Objetivo |
|:-------|:-----|:------------|:------------------|
| `POST` | `/artifacts/upload` | Sube un fichero asociado a una sesión y nodo | Artifact Service |
| `GET` | `/artifacts/download` | Descarga un artefacto por bucket y key | Artifact Service |
| `GET` | `/artifacts/preview` | Previsualiza los primeros bytes de un artefacto | Artifact Service |

#### Endpoints de Workflows

| Método | Ruta | Descripción | Servicio Objetivo |
|:-------|:-----|:------------|:------------------|
| `POST` | `/workflow/submit` | Compila y envía un workflow a Argo | Execution Service |
| `POST` | `/workflow/compile` | Compila un workflow sin enviarlo | Workflow Service |
| `POST` | `/workflow/render` | Renderiza el manifiesto YAML para previsualización | Workflow Service |
| `GET` | `/workflow/status` | Consulta el estado de un workflow en ejecución | Execution Service |
| `GET` | `/workflow/logs/stream` | Streaming de logs de un workflow | Execution Service |
| `POST` | `/workflow/output-artifacts` | Lista artefactos de salida de un workflow | Artifact Service |

#### Endpoints de Definiciones Guardadas

| Método | Ruta | Descripción | Servicio Objetivo |
|:-------|:-----|:------------|:------------------|
| `POST` | `/workflows` | Guarda una definición de workflow | Workflow Service |
| `GET` | `/workflows` | Lista todas las definiciones guardadas | Workflow Service |
| `GET` | `/workflows/{id}` | Obtiene una definición específica | Workflow Service |

#### Endpoints de Catálogo

| Método | Ruta | Descripción | Servicio Objetivo |
|:-------|:-----|:------------|:------------------|
| `GET` | `/templates` | Lista todos los templates de nodos disponibles | Catalog Service |

#### Endpoints de Validación

| Método | Ruta | Descripción | Servicio Objetivo |
|:-------|:-----|:------------|:------------------|
| `POST` | `/images/validate` | Valida si las imágenes de ciertos templates existen | Catalog Service |
| `GET` | `/images/validate-all` | Valida todas las imágenes del catálogo | Catalog Service |

#### Endpoints de Sistema

| Método | Ruta | Descripción | Servicio Objetivo |
|:-------|:-----|:------------|:------------------|
| `GET` | `/health` | Health check para Kubernetes liveness/readiness | API Gateway |

---

## Catálogo de Nodos de Workflow

Además de los servicios, la plataforma define un **catálogo de nodos** que representa los tipos de procesamiento disponibles. Cada nodo es un paso atómico que se puede arrastrar al canvas y conectar con otros.

### Estructura de un Nodo

Cada nodo en el catálogo tiene la siguiente estructura:

```yaml
- name: preprocessing          # Identificador único
  type: preprocessing          # Categoría (input, preprocessing, training, generation, output)
  version: v2                  # Versión del nodo
  parameters: [config]         # Parámetros configurables por el usuario
  parameters_file: path/to/defaults.json  # Valores por defecto
  artifacts:
    inputs:
      - name: source-data
        path: /data/inputs/input.csv
      - name: preprocessing-config
        path: /data/config/preprocessing.yaml
    outputs:
      - name: processed-data
        path: /data/outputs/preprocessed_input.csv
  limits: {}                   # Límites de CPU/memoria (opcional)
```

### Catálogo Actual del Prototipo

El prototipo incluye los siguientes nodos:

#### Nodos de Entrada/Salida

| Nodo | Tipo | Descripción |
|:-----|:-----|:------------|
| `data-input` | input | Punto de entrada para datasets del usuario |
| `data-output` | output | Punto de salida para visualizar resultados |

#### Nodos de Preprocesamiento

| Nodo | Tipo | Descripción |
|:-----|:-----|:------------|
| `preprocessing` | preprocessing | Limpieza y transformación de datos tabulares |

#### Nodos de Entrenamiento

| Nodo | Tipo | Descripción |
|:-----|:-----|:------------|
| `train-hmm-model` | training | Entrena un modelo Hidden Markov Model |
| `train-gaussian-process-model` | training | Entrena un modelo Gaussian Process |
| `train-copulas-model` | training | Entrena un modelo basado en Copulas |
| `train-boltzman-machines-model` | training | Entrena una Restricted Boltzmann Machine |
| `train-bayesian-networks-model` | training | Entrena una Red Bayesiana |
| `train-gym-pybullet-rl` | training | Entrena un agente de Reinforcement Learning |

#### Nodos de Generación

| Nodo | Tipo | Descripción |
|:-----|:-----|:------------|
| `generate-hmm-data` | generation | Genera datos sintéticos con HMM |
| `generate-gaussian-process-data` | generation | Genera datos sintéticos con GP |
| `generate-copulas-data` | generation | Genera datos sintéticos con Copulas |
| `generate-boltzman-machines-data` | generation | Genera datos sintéticos con RBM |
| `generate-bayesian-networks-data` | generation | Genera datos sintéticos con BN |
| `bouncing-ball` | generation | Simulación física de una pelota (Unity) |

### Extensibilidad del Catálogo

El catálogo está diseñado para ser fácilmente extensible:

1. **Añadir nuevo nodo**: Crear entrada en `catalog/nodes.yaml` + imagen Docker.
2. **Crear template de Argo**: Añadir definición en `workflow-templates.yaml`.
3. **Parámetros por defecto**: Fichero JSON con valores iniciales.

No se requiere modificar código del backend para añadir nuevos tipos de nodos.

---

## Contratos de API

### Ejemplo: Envío de Workflow

**Request:**
```http
POST /workflow/submit
Content-Type: application/json

{
  "sessionId": "abc-123-def",
  "nodes": [
    {
      "id": "node-1",
      "type": "customNode",
      "data": {
        "label": "Input Data",
        "templateName": "data-input",
        "uploadedArtifact": {
          "bucket": "argo-artifacts",
          "key": "sessions/abc/nodes/node-1/dataset.csv"
        }
      }
    },
    {
      "id": "node-2",
      "type": "customNode",
      "data": {
        "label": "Preprocessing",
        "templateName": "preprocessing",
        "parameters": {"normalize": true}
      }
    }
  ],
  "edges": [
    {"source": "node-1", "target": "node-2"}
  ]
}
```

**Response:**
```json
{
  "workflowName": "sds-abc-123-def-xyz",
  "namespace": "argo",
  "nodeSlugMap": {
    "node-1": "data-input",
    "node-2": "preprocessing"
  },
  "bucket": "argo-artifacts",
  "key": "sessions/abc/workflow/workflow-abc.yaml",
  "manifestFilename": "workflow-abc.yaml"
}
```

### Ejemplo: Consulta de Estado

**Request:**
```http
GET /workflow/status?workflowName=sds-abc-123-def-xyz
```

**Response:**
```json
{
  "workflowName": "sds-abc-123-def-xyz",
  "namespace": "argo",
  "phase": "Running",
  "finished": false,
  "nodes": {
    "data-input": {
      "slug": "data-input",
      "phase": "Succeeded",
      "startedAt": "2024-01-15T10:00:00Z",
      "finishedAt": "2024-01-15T10:00:05Z"
    },
    "preprocessing": {
      "slug": "preprocessing",
      "phase": "Running",
      "startedAt": "2024-01-15T10:00:06Z"
    }
  }
}
```

---

## Comparativa: Arquitectura Objetivo vs Prototipo

| Aspecto | Arquitectura Objetivo | Prototipo Actual |
|:--------|:----------------------|:-----------------|
| **Número de servicios** | 6-8 servicios especializados | 1 backend monolítico |
| **API Gateway** | Kong/Traefik con autenticación | CORS permisivo, sin auth |
| **Autenticación** | OAuth2/OIDC + RBAC | No implementado |
| **Base de datos** | PostgreSQL para metadatos | MinIO para todo (JSON) |
| **Catálogo de nodos** | Servicio con versionado y deprecación | Fichero YAML estático |
| **Notificaciones** | Webhooks + email | No implementado |
| **Métricas de negocio** | Servicio dedicado con dashboards | Logs básicos |

El prototipo demuestra que la arquitectura funciona. La evolución hacia producción implica:
1. Separar el monolito en servicios según los módulos actuales.
2. Añadir la capa de autenticación/autorización.
3. Introducir PostgreSQL para metadatos.
4. Configurar el API Gateway.
