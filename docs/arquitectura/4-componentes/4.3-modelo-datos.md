# 4.3. Modelo de Datos

## Introducción

Este apartado describe el modelo de datos de la plataforma: las entidades que maneja, sus relaciones, y cómo se almacenan. Se distingue entre:

1. **Datos estructurados**: Definiciones de workflows, usuarios, histórico de ejecuciones.
2. **Datos no estructurados**: Artefactos (datasets, modelos, resultados).

En la **arquitectura objetivo**, los datos estructurados se almacenan en PostgreSQL, mientras que los artefactos residen en MinIO/S3. En el **prototipo actual**, todo se almacena en MinIO como ficheros JSON/binarios.

---

## Diagrama Entidad-Relación Conceptual

El siguiente diagrama muestra las entidades principales del sistema y sus relaciones. Es un modelo conceptual que representa el diseño lógico, independientemente de si se implementa con SQL, NoSQL o ficheros.

![Data Model](diagrams/4.3-data-model.puml)

### Dominios del Sistema

El modelo se organiza en cuatro dominios:

| Dominio | Descripción | Persistencia Objetivo | Persistencia Prototipo |
|:--------|:------------|:----------------------|:-----------------------|
| **User Domain** | Usuarios y permisos | PostgreSQL | No implementado |
| **Workflow Definition** | Definiciones guardadas | PostgreSQL + MinIO | MinIO (JSON) |
| **Catalog** | Templates de nodos | PostgreSQL (versionado) | YAML estático |
| **Execution** | Histórico de ejecuciones | PostgreSQL | Argo + MinIO |

---

## Modelo Detallado por Dominio

### 1. User Domain (Usuarios y Permisos)

#### Entidades

**User**
```typescript
interface User {
  id: UUID;                  // Identificador único
  email: string;             // Email (único)
  name: string;              // Nombre para mostrar
  role: RoleId;              // Referencia al rol
  createdAt: DateTime;       // Fecha de creación
  lastLoginAt?: DateTime;    // Último acceso
}
```

**Role**
```typescript
interface Role {
  id: string;                // Identificador (ej: "admin", "developer")
  name: string;              // Nombre legible
  permissions: Permission[]; // Lista de permisos
}
```

#### Roles Objetivo

| Rol | Permisos |
|:----|:---------|
| **admin** | Gestión de usuarios, configuración de plataforma, acceso total |
| **developer** | Crear/editar/ejecutar workflows propios |
| **viewer** | Solo lectura de workflows compartidos |

#### Estado del Prototipo

El prototipo no implementa autenticación. Todos los usuarios tienen acceso completo sin identificación.

---

### 2. Workflow Definition Domain

Este dominio contiene las definiciones de workflows guardados por los usuarios.

#### Entidades

**WorkflowDefinition**

Representa una definición de workflow guardada.

```typescript
interface WorkflowDefinition {
  id: UUID;                      // Identificador único
  name: string;                  // Nombre legible
  description?: string;          // Descripción opcional
  ownerId: UUID;                 // Usuario propietario
  sessionId: string;             // ID de sesión del canvas
  version: number;               // Versión del workflow
  createdAt: DateTime;           // Fecha de creación
  updatedAt: DateTime;           // Última modificación
  
  // Contenido del workflow (grafo)
  graph: FlowGraph;
  
  // Manifiesto compilado (si existe)
  compiledManifest?: string;     // YAML de Argo
  manifestFilename?: string;     // Nombre del fichero
  compiledAt?: DateTime;         // Cuándo se compiló
  
  // Última ejecución
  lastWorkflowName?: string;     // Nombre en Argo
  lastNamespace?: string;        // Namespace de ejecución
  lastSubmittedAt?: DateTime;    // Cuándo se envió
}
```

**FlowGraph**

Representa el grafo visual del canvas.

```typescript
interface FlowGraph {
  nodes: FlowNode[];             // Nodos del grafo
  edges: FlowEdge[];             // Conexiones entre nodos
}
```

**FlowNode**

Cada nodo en el canvas.

```typescript
interface FlowNode {
  id: string;                    // ID único del nodo
  type: string;                  // Tipo de nodo (ej: "customNode")
  position: { x: number; y: number };  // Posición en el canvas
  data: NodeData;                // Datos del nodo
}
```

**NodeData**

Datos específicos de cada nodo.

```typescript
interface NodeData {
  label: string;                 // Etiqueta visible
  templateName: string;          // Template del catálogo
  parameters?: Record<string, any>;  // Parámetros configurados
  parameterDefaults?: Record<string, any>;  // Valores por defecto
  uploadedArtifact?: {           // Artefacto subido (para nodos input)
    bucket: string;
    key: string;
    size?: number;
    contentType?: string;
    originalFilename?: string;
  };
}
```

**FlowEdge**

Conexión entre dos nodos.

```typescript
interface FlowEdge {
  id: string;                    // ID único
  source: string;                // ID del nodo origen
  target: string;                // ID del nodo destino
  sourceHandle?: string;         // Handle de salida específico
  targetHandle?: string;         // Handle de entrada específico
}
```

#### Grafo como DAG

El grafo definido por nodes/edges debe ser un **DAG (Directed Acyclic Graph)**:

- **Dirigido**: Las aristas tienen dirección (source → target)
- **Acíclico**: No pueden existir ciclos

El backend valida estas propiedades antes de compilar:

```python
def validate_dag(nodes, edges):
    # Construir grafo de adyacencia
    graph = {node.id: [] for node in nodes}
    for edge in edges:
        graph[edge.source].append(edge.target)
    
    # Detectar ciclos con DFS
    visited = set()
    rec_stack = set()
    
    def has_cycle(node):
        visited.add(node)
        rec_stack.add(node)
        for neighbor in graph[node]:
            if neighbor not in visited:
                if has_cycle(neighbor):
                    return True
            elif neighbor in rec_stack:
                return True
        rec_stack.remove(node)
        return False
    
    for node in graph:
        if node not in visited:
            if has_cycle(node):
                raise ValidationError("Cycle detected in workflow")
```

#### Almacenamiento en Prototipo

En el prototipo, cada WorkflowDefinition se guarda como un fichero JSON en MinIO:

```
argo-artifacts/
└── workflows/
    └── {workflow_id}.json
```

Ejemplo de fichero:

```json
{
  "workflowId": "a1b2c3d4",
  "name": "Mi Workflow de Prueba",
  "description": "Genera datos sintéticos con HMM",
  "sessionId": "session-xyz",
  "nodes": [
    {"id": "node-1", "type": "customNode", "data": {"templateName": "data-input", ...}},
    {"id": "node-2", "type": "customNode", "data": {"templateName": "preprocessing", ...}}
  ],
  "edges": [
    {"source": "node-1", "target": "node-2"}
  ],
  "compiledManifest": "apiVersion: argoproj.io...",
  "createdAt": "2024-01-15T10:00:00Z",
  "updatedAt": "2024-01-15T12:30:00Z"
}
```

---

### 3. Catalog Domain

El catálogo define los tipos de nodos disponibles para arrastrar al canvas.

#### Entidades

**NodeTemplate**

```typescript
interface NodeTemplate {
  name: string;                  // Identificador único
  type: NodeType;                // Categoría
  version: string;               // Versión (ej: "v2")
  parameters: string[];          // Parámetros configurables
  parameterDefaults?: Record<string, any>;  // Valores por defecto
  artifacts: Artifacts;          // Entrada/salida
  limits?: ResourceLimits;       // Límites de CPU/memoria
}

type NodeType = 
  | "input"          // Punto de entrada de datos
  | "preprocessing"  // Transformación de datos
  | "training"       // Entrenamiento de modelo
  | "generation"     // Generación de datos
  | "output";        // Punto de salida
```

**Artifacts**

```typescript
interface Artifacts {
  inputs: ArtifactSpec[];        // Artefactos de entrada
  outputs: ArtifactSpec[];       // Artefactos de salida
}

interface ArtifactSpec {
  name: string;                  // Nombre lógico
  path: string;                  // Ruta dentro del contenedor
}
```

#### Catálogo YAML del Prototipo

El prototipo carga el catálogo desde `backend/catalog/nodes.yaml`:

```yaml
nodes:
  - name: preprocessing
    type: preprocessing
    version: v2
    parameters: [config]
    artifacts:
      inputs:
        - name: source-data
          path: /data/inputs/input.csv
        - name: preprocessing-config
          path: /data/config/preprocessing.yaml
      outputs:
        - name: processed-data
          path: /data/outputs/preprocessed_input.csv
```

#### Arquitectura Objetivo

En producción, el catálogo se almacenaría en PostgreSQL para:

- **Versionado**: Historial de cambios por template
- **Deprecación**: Marcar versiones obsoletas
- **Auditoría**: Quién modificó qué y cuándo
- **Multi-tenant**: Catálogos específicos por organización

---

### 4. Execution Domain

Este dominio captura el histórico de ejecuciones de workflows.

#### Entidades

**WorkflowExecution**

```typescript
interface WorkflowExecution {
  id: UUID;                      // Identificador interno
  workflowName: string;          // Nombre en Argo (ej: "sds-abc-xyz")
  namespace: string;             // Namespace de K8s
  definitionId: UUID;            // Referencia al workflow guardado
  userId: UUID;                  // Usuario que ejecutó
  phase: ExecutionPhase;         // Estado global
  startedAt: DateTime;           // Inicio
  finishedAt?: DateTime;         // Fin (si terminó)
  duration?: number;             // Duración en segundos
  resourceUsage?: ResourceMetrics;  // CPU/memoria consumidos
}

type ExecutionPhase = 
  | "Pending"
  | "Running"
  | "Succeeded"
  | "Failed"
  | "Error"
  | "Skipped";
```

**NodeExecution**

```typescript
interface NodeExecution {
  executionId: UUID;             // Ejecución padre
  slug: string;                  // Identificador del paso
  nodeId: string;                // Referencia al nodo del grafo
  phase: ExecutionPhase;         // Estado del paso
  podName?: string;              // Nombre del pod en K8s
  startedAt?: DateTime;          // Inicio
  finishedAt?: DateTime;         // Fin
  message?: string;              // Mensaje de error/éxito
  exitCode?: number;             // Código de salida del contenedor
}
```

#### Persistencia en Prototipo

El prototipo no almacena las ejecuciones en una base de datos propia. En su lugar:

- **Estado actual**: Se consulta directamente a Argo Server vía API
- **Histórico**: Argo mantiene el histórico en su propia base de datos
- **Artefactos**: Quedan en MinIO referenciados por path

#### Arquitectura Objetivo

En producción, se replicaría información de ejecuciones a PostgreSQL para:

- **Búsquedas**: Encontrar ejecuciones por usuario, fecha, estado
- **Métricas de negocio**: Tiempo medio de ejecución, tasa de fallos
- **Auditoría**: Cumplimiento normativo
- **Dashboards**: Grafana con datos de uso

---

## Decisión de Almacenamiento

### Arquitectura Objetivo

| Tipo de Dato | Tecnología | Justificación |
|:-------------|:-----------|:--------------|
| **Metadatos estructurados** | PostgreSQL | Consultas SQL, índices, transacciones ACID |
| **Artefactos binarios** | MinIO/S3 | Escalable, compatible con Argo, sin límite de tamaño |
| **Catálogo de nodos** | PostgreSQL | Versionado, deprecación, multi-tenant |
| **Logs de ejecución** | S3 + Loki | Volumen alto, retención configurable |
| **Métricas** | Prometheus | Series temporales, alertas |

### Estado del Prototipo

| Tipo de Dato | Tecnología | Limitación |
|:-------------|:-----------|:-----------|
| **Workflows guardados** | MinIO (JSON) | Sin índices, búsqueda lenta |
| **Artefactos** | MinIO | ✅ Funcional |
| **Catálogo** | YAML en disco | Sin versionado dinámico |
| **Ejecuciones** | Argo Server | Sin auditoría propia |

---

## Esquema PostgreSQL Objetivo

Para la arquitectura objetivo, el esquema de PostgreSQL sería:

```sql
-- Usuarios y autenticación
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    role_id VARCHAR(50) NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    last_login_at TIMESTAMPTZ
);

CREATE TABLE roles (
    id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    permissions JSONB NOT NULL DEFAULT '[]'
);

-- Definiciones de workflows
CREATE TABLE workflow_definitions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    owner_id UUID REFERENCES users(id),
    session_id VARCHAR(255) NOT NULL,
    version INT DEFAULT 1,
    graph JSONB NOT NULL,
    compiled_manifest TEXT,
    manifest_filename VARCHAR(255),
    compiled_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_workflows_owner ON workflow_definitions(owner_id);
CREATE INDEX idx_workflows_updated ON workflow_definitions(updated_at DESC);

-- Histórico de ejecuciones
CREATE TABLE workflow_executions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    workflow_name VARCHAR(255) NOT NULL,
    namespace VARCHAR(255) NOT NULL,
    definition_id UUID REFERENCES workflow_definitions(id),
    user_id UUID REFERENCES users(id),
    phase VARCHAR(50),
    started_at TIMESTAMPTZ,
    finished_at TIMESTAMPTZ,
    duration_seconds INT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_executions_user ON workflow_executions(user_id);
CREATE INDEX idx_executions_phase ON workflow_executions(phase);
CREATE INDEX idx_executions_started ON workflow_executions(started_at DESC);

-- Catálogo de nodos (versionado)
CREATE TABLE node_templates (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    type VARCHAR(50) NOT NULL,
    version VARCHAR(50) NOT NULL,
    parameters JSONB DEFAULT '[]',
    parameter_defaults JSONB,
    artifacts JSONB NOT NULL,
    limits JSONB,
    deprecated BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(name, version)
);

CREATE INDEX idx_templates_name ON node_templates(name);
CREATE INDEX idx_templates_type ON node_templates(type);
```

---

## Justificación: SQL vs NoSQL

### ¿Por qué PostgreSQL para Metadatos?

| Característica | PostgreSQL | MongoDB/DynamoDB |
|:---------------|:-----------|:-----------------|
| **Consistencia** | ACID garantizado | Eventual consistency |
| **Relaciones** | JOINs nativos | Denormalización manual |
| **Índices** | Múltiples tipos (B-tree, GIN para JSON) | Limitados |
| **Madurez** | 30+ años | 15 años |
| **Comunidad K8s** | Operadores probados | Operadores menos maduros |

PostgreSQL también soporta JSONB, lo que permite almacenar el grafo del workflow como JSON dentro de una tabla relacional, combinando lo mejor de ambos mundos.

### ¿Por qué MinIO/S3 para Artefactos?

| Característica | MinIO/S3 | PostgreSQL BLOB |
|:---------------|:---------|:----------------|
| **Tamaño** | Sin límite práctico | Mejor < 1GB por fila |
| **Streaming** | Sí, multipart | Menos eficiente |
| **Compatibilidad Argo** | Nativo | Requiere adaptador |
| **Escalabilidad** | Horizontal fácil | Vertical principalmente |
| **Coste** | Muy bajo por TB | Alto por TB |

---

## Migración Prototipo → Producción

Para evolucionar del prototipo a la arquitectura objetivo:

### Paso 1: Introducir PostgreSQL

1. Desplegar PostgreSQL en el cluster (StatefulSet)
2. Crear esquema con tablas vacías
3. Mantener MinIO para artefactos

### Paso 2: Migrar Workflows Guardados

```python
# Script de migración
def migrate_workflows_to_postgres():
    minio = get_minio_client()
    pg = get_postgres_connection()
    
    for obj in minio.list_objects("argo-artifacts", "workflows/"):
        data = minio.get_object(obj.object_name)
        workflow = json.loads(data.read())
        
        pg.execute("""
            INSERT INTO workflow_definitions 
            (id, name, description, session_id, graph, compiled_manifest, ...)
            VALUES (%s, %s, %s, %s, %s, %s, ...)
        """, (
            workflow['workflowId'],
            workflow['name'],
            workflow.get('description'),
            workflow['sessionId'],
            json.dumps({'nodes': workflow['nodes'], 'edges': workflow['edges']}),
            workflow.get('compiledManifest'),
            ...
        ))
```

### Paso 3: Migrar Catálogo

1. Cargar `nodes.yaml` → INSERT en `node_templates`
2. Modificar `catalog_loader.py` para leer de PostgreSQL
3. Añadir endpoint para gestión dinámica

### Paso 4: Añadir Tracking de Ejecuciones

1. En cada submit, INSERT en `workflow_executions`
2. Hook al finalizar para actualizar phase/finished_at
3. Opcional: webhook de Argo para actualizaciones en tiempo real

---

## Resumen Comparativo

| Aspecto | Arquitectura Objetivo | Prototipo Actual |
|:--------|:----------------------|:-----------------|
| **Metadatos** | PostgreSQL con esquema relacional | MinIO (JSON files) |
| **Artefactos** | MinIO/S3 | MinIO |
| **Catálogo** | PostgreSQL con versionado | YAML estático |
| **Ejecuciones** | PostgreSQL + Argo | Solo Argo |
| **Usuarios** | PostgreSQL + OIDC | No implementado |
| **Búsquedas** | SQL con índices | Escaneo secuencial |
| **Backups** | pg_dump + S3 replication | Ninguno automático |
